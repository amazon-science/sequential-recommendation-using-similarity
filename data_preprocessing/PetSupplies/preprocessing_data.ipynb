{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import wget\n",
    "import gzip\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/\"\n",
    "reviews_path = \"reviews_Pet_Supplies.json.gz\"\n",
    "meta_path = \"meta_Pet_Supplies.json.gz\"\n",
    "\n",
    "# download raw dataset\n",
    "if not os.path.exists(reviews_path):\n",
    "    wget.download(base_url + reviews_path)\n",
    "if not os.path.exists(meta_path):\n",
    "    wget.download(base_url + meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_FREQ_MIN = 5\n",
    "REVIEWS_REMOVE_LESS_THAN = 5\n",
    "\n",
    "out_path = \"Pet.txt\"\n",
    "id_to_title_map_path = \"Pet-titles.txt\"\n",
    "id_to_asin_map_path = \"Pet-id_to_asin.txt\"\n",
    "train_item_freq_path = \"Pet-train_item_freq.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load items data\n",
    "items = dict()\n",
    "skipped = 0\n",
    "with gzip.open(meta_path, \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        json_obj = eval(line)\n",
    "        asin = json_obj['asin']\n",
    "        if 'title' in json_obj:\n",
    "            title = json_obj['title'].replace(\"\\\"\", \"'\")\n",
    "            title = title.replace(\"\\n\", \" \").replace('&quot;', '\\\\\"').replace('&amp;', '&').replace('&reg;', '').replace('&trade;', '').replace('&eacute;', 'e').replace('&deg;', '').replace('&lt;', '<').replace('&gt;', '>').replace('&nbsp;', ' ').replace('&frac', '/')\n",
    "            if len(title) >= 2:\n",
    "                items[asin] = title\n",
    "            else:\n",
    "                skipped +=1\n",
    "        else:\n",
    "            skipped += 1\n",
    "\n",
    "print(f\"Found {len(items)} items\")\n",
    "print(f\"Skipped {skipped} items without title\")\n",
    "\n",
    "# load reviews data\n",
    "reviews = defaultdict(list)\n",
    "item_freq = defaultdict(int)\n",
    "skipped = 0\n",
    "with gzip.open(reviews_path, \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        json_obj = eval(line)\n",
    "        user_id = json_obj['reviewerID']\n",
    "        asin = json_obj['asin']\n",
    "        timestemp = json_obj['unixReviewTime']\n",
    "        if asin in items:\n",
    "            reviews[user_id].append((asin, int(timestemp)))\n",
    "            item_freq[asin] += 1\n",
    "        else:\n",
    "            skipped += 1\n",
    "            # print(f\"skipped {asin}\")\n",
    "\n",
    "print(f\"Found {len(reviews)} users\")\n",
    "print(f\"Found {sum(item_freq.values())} reviews\")\n",
    "print(f\"Skipepd {skipped} item reviews without metadata\")\n",
    "\n",
    "item_freq = {k: v for k, v in item_freq.items() if v >= ITEM_FREQ_MIN}\n",
    "\n",
    "item_freq = dict(sorted(item_freq.items()))\n",
    "\n",
    "# remove user with less than K reviews\n",
    "removed_users_less_than = 0\n",
    "removed_users_item_less_than = 0\n",
    "removed_items = 0\n",
    "updated_items = set()\n",
    "for user_id in list(reviews.keys()):\n",
    "    if len(reviews[user_id]) < REVIEWS_REMOVE_LESS_THAN:\n",
    "        del reviews[user_id]\n",
    "        removed_users_less_than += 1\n",
    "    else:\n",
    "        len_before = len(reviews[user_id])\n",
    "        reviews[user_id] = [item for item in reviews[user_id] if item[0] in item_freq]\n",
    "        updated_items.update([t[0] for t in reviews[user_id]])\n",
    "        removed_items += len_before - len(reviews[user_id])\n",
    "        if len(reviews[user_id]) <= 0:\n",
    "            del reviews[user_id]\n",
    "            removed_users_item_less_than += 1\n",
    "print(f\"Removed {removed_items} reviews of items that appear less than {ITEM_FREQ_MIN} in total\")\n",
    "print(f\"Removed {removed_users_less_than} users with less than {REVIEWS_REMOVE_LESS_THAN} actions\")\n",
    "print(f\"Removed {removed_users_item_less_than} users with only item count less than {REVIEWS_REMOVE_LESS_THAN}\")\n",
    "\n",
    "# calculate item frequencey again \n",
    "original_item_freq = item_freq\n",
    "item_freq = defaultdict(int)\n",
    "for user_id, rating_list in reviews.items():\n",
    "    for item, timestamp in rating_list:\n",
    "        item_freq[item] += 1\n",
    "        \n",
    "item_freq = dict(sorted(item_freq.items()))\n",
    "print(f\"Total of {sum(item_freq.values())} reviews\")\n",
    "\n",
    "# remove \"unused\" items\n",
    "new_items = {}\n",
    "new_item_freq = {}\n",
    "new_original_item_freq = {}\n",
    "for asin in tqdm(updated_items):\n",
    "    new_items[asin] = items[asin]\n",
    "    new_item_freq[asin] = item_freq[asin]\n",
    "    new_original_item_freq[asin] = original_item_freq[asin]\n",
    "print(f\"Removed {len(items) - len(new_items)} items that are not been reviewd\")\n",
    "item_freq = new_item_freq\n",
    "items = new_items\n",
    "original_item_freq = new_original_item_freq\n",
    "\n",
    "\n",
    "print()\n",
    "print(f\"Items   Reviews   Users\")\n",
    "print(f\"{len(items):<4}   {sum(len(v) for v in reviews.values()):<7}   {len(reviews):<5}\")\n",
    "\n",
    "# fix user id\n",
    "user_id_mapping = dict()\n",
    "i = 0\n",
    "for original_user_id in reviews:\n",
    "    user_id_mapping[original_user_id] = i\n",
    "    i += 1\n",
    "\n",
    "# fix items ids\n",
    "item_id_mapping = dict()\n",
    "i = 0\n",
    "for asin in items:\n",
    "    item_id_mapping[asin] = i\n",
    "    i += 1\n",
    "\n",
    "train_item_freq = {k: 0 for k in item_freq.keys()}\n",
    "val_item_freq = {k: 0 for k in item_freq.keys()}\n",
    "test_item_freq = {k: 0 for k in item_freq.keys()}\n",
    "for user_id, rating_list in reviews.items():\n",
    "    sorted_list = list(map(lambda t: t[0], sorted(rating_list, key=lambda t: t[1])))\n",
    "    if len(sorted_list) < 3:\n",
    "        train_list = sorted_list\n",
    "    else:\n",
    "        train_list = sorted_list[1:-2]\n",
    "        val_item_freq[sorted_list[-2]] += 1\n",
    "        test_item_freq[sorted_list[-1]] += 1    \n",
    "    for asin in train_list:\n",
    "        train_item_freq[asin] += 1\n",
    " \n",
    "\n",
    "with open(out_path, \"w\") as f:\n",
    "    for user_id, rating_list in reviews.items():\n",
    "        sorted_list = sorted(rating_list, key=lambda t: t[1])\n",
    "        for asin, timestamp in sorted_list:\n",
    "            f.write(f\"{user_id_mapping[user_id] + 1} {item_id_mapping[asin] + 1}\\n\") # start user id from 1 to match original SASRec paper,reserve the 0 index for padding\n",
    "\n",
    "with open(id_to_title_map_path, \"w\") as f:\n",
    "    for asin, title in items.items():\n",
    "        f.write(f'{item_id_mapping[asin]} \"{title}\"\\n')\n",
    "\n",
    "with open(id_to_asin_map_path, \"w\") as f:\n",
    "    for asin, item_id in item_id_mapping.items():\n",
    "        f.write(f'{item_id} {asin}\\n')\n",
    "\n",
    "with open(train_item_freq_path, \"w\") as f:\n",
    "    for asin, count in train_item_freq.items():\n",
    "        f.write(f'{item_id_mapping[asin]} {count}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
